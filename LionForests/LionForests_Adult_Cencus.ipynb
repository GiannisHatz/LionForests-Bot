{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains the experiments on Adult Census dataset with LionForests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler, LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from LionForests import LionForests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we load the dataset and we set the feature and class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country','salary']\n",
    "class_names=['<=50K','>50K'] #0: <=50K and 1: >50K\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', names=feature_names, delimiter=', ')\n",
    "data_test = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test', names=feature_names, delimiter=', ')\n",
    "data_test = data_test.drop(data_test.index[[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are doing the following preprocessing influenced by a github notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data != '?').all(axis=1)]\n",
    "data_test = data_test[(data_test != '?').all(axis=1)]\n",
    "data_test['salary'] = data_test['salary'].map({'<=50K.': '<=50K', '>50K.': '>50K'})\n",
    "frames = [data, data_test]\n",
    "data = pd.concat(frames)\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering from:\n",
    "https://github.com/pooja2512/Adult-Census-Income/blob/master/Adult%20Census%20Income.ipynb. So run and skip the next code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hs_grad = ['HS-grad','11th','10th','9th','12th']\n",
    "elementary = ['1st-4th','5th-6th','7th-8th']\n",
    "# replace elements in list.\n",
    "for i in hs_grad:\n",
    "    data['education'].replace(i , 'HS-grad', regex=True , inplace=True)\n",
    "for e in elementary:\n",
    "    data['education'].replace(e , 'elementary-school', regex=True, inplace = True)\n",
    "\n",
    "married= ['Married-spouse-absent','Married-civ-spouse','Married-AF-spouse']\n",
    "separated = ['Separated','Divorced']\n",
    "#replace elements in list.\n",
    "for m in married:\n",
    "    data['marital-status'].replace(m ,'Married', regex=True, inplace = True)\n",
    "for s in separated:\n",
    "    data['marital-status'].replace(s ,'Separated', regex=True, inplace = True)\n",
    "\n",
    "self_employed = ['Self-emp-not-inc','Self-emp-inc']\n",
    "govt_employees = ['Local-gov','State-gov','Federal-gov']\n",
    "for se in self_employed:\n",
    "    data['workclass'].replace(se , 'Self_employed', regex=True, inplace = True)\n",
    "for ge in govt_employees:\n",
    "    data['workclass'].replace(ge , 'Govt_employees', regex=True, inplace = True)\n",
    "\n",
    "del_cols = ['relationship','education-num']\n",
    "data.drop(labels = del_cols, axis = 1, inplace = True)\n",
    "\n",
    "index_age = data[data['age'] == 90].index\n",
    "data.drop(labels = index_age, axis = 0, inplace =True)\n",
    "num_col_new = ['age','capital-gain', 'capital-loss',\n",
    "       'hours-per-week','fnlwgt']\n",
    "cat_col_new = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "               'race', 'sex','salary','native-country']#add native-country label\n",
    "scaler = MinMaxScaler()\n",
    "#pd.DataFrame(scaler.fit_transform(data[num_col_new]),columns = num_col_new)\n",
    "class DataFrameSelector(TransformerMixin):\n",
    "    def __init__(self,attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X[self.attribute_names]\n",
    "class num_trans(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        df = pd.DataFrame(X)\n",
    "        df.columns = num_col_new \n",
    "        return df\n",
    "pipeline = Pipeline([('selector',DataFrameSelector(num_col_new)),  \n",
    "                     ('scaler',MinMaxScaler()),('transform',num_trans())])#('scaler',MinMaxScaler()),        \n",
    "num_df = pipeline.fit_transform(data)\n",
    "num_df.shape\n",
    "# columns which I don't need after creating dummy variables dataframe\n",
    "cols = ['workclass_Govt_employess','education_Some-college',\n",
    "        'marital-status_Never-married','occupation_Other-service',\n",
    "        'race_Black','sex_Male','salary_>50K']\n",
    "class dummies(TransformerMixin):\n",
    "    def __init__(self,cols):\n",
    "        self.cols = cols\n",
    "    \n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        df = pd.get_dummies(X)\n",
    "        df_new = df[df.columns.difference(cols)] \n",
    "        return df_new\n",
    "pipeline_cat=Pipeline([('selector',DataFrameSelector(cat_col_new)),\n",
    "                      ('dummies',dummies(cols))])\n",
    "cat_df = pipeline_cat.fit_transform(data)\n",
    "cat_df['id'] = pd.Series(range(cat_df.shape[0]))\n",
    "num_df['id'] = pd.Series(range(num_df.shape[0]))\n",
    "final_df = pd.merge(cat_df,num_df,how = 'inner', on = 'id')\n",
    "print(f\"Number of observations in final dataset: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the train and target data from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = final_df['salary_<=50K'].values\n",
    "final_df.drop(labels = ['id','salary_<=50K'],axis = 1,inplace = True)\n",
    "X = final_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we need the new onehot encoded features' names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(final_df.columns.values)\n",
    "categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'race', 'sex','native-country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We declare the name of the categorical features in order LionForests to extract more compact explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "parameters = [{\n",
    "    'max_depth': [10],\n",
    "    'max_features': ['sqrt'],\n",
    "    'bootstrap': [False],\n",
    "    'min_samples_leaf' : [1],\n",
    "    'n_estimators': [100]\n",
    "}]\n",
    "lf = LionForests(class_names=class_names)\n",
    "lf.train(X, y, my_scaler, feature_names, None, categorical_features) #Please do not ascale data before training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we use the build-in GridSearch of LionForests to find the best classifier for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "number_of_estimators = lf.model.n_estimators\n",
    "print(\"Accuracy:\",lf.accuracy,\", Number of estimators:\",lf.number_of_estimators)\n",
    "print(lf.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to extract explanations about an instance. We choose the eleventh instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lf_rule = lf.following_breadcrumbs(X[10], False, True, False, complexity=2)\n",
    "print(lf_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original rule would have been this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "discrete_features = ['age']\n",
    "lf.check_changes_in_prediction (X[10],lf_rule, discrete_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, some categorical alternative values got reduced. Currently, LionForests do not extract them automatically, but it will be implemented soon. You can notice that fnlwgt, age, hours per week and capital gain and loss values were not inverse transformed from LionForests. This is happening because we preprocessed this data externally. Thus we have to inverse transform them manually. If you want check instance 882 too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
